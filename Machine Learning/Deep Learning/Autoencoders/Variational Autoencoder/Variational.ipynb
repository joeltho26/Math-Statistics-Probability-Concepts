{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "270ca4b6",
   "metadata": {},
   "source": [
    "1. [Variational Autoencoder](#variational-autoencoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c699d9ec",
   "metadata": {},
   "source": [
    "#### Variational Autoencoder:\n",
    "- it learns a probabilistic mapping to a latent distribution instead learning a deterministic mapping to a fixed latent vector\n",
    "- a sample is then drawn from this distribution (using the \"reparameterization trick\" to allow backpropagation) and fed to the decoder\n",
    "- loss function includes both the reconstruction error and a Kullback-Leibler (KL) divergence term that regularizes the learned latent distribution to be close to a prior distribution\n",
    "- used in Generative modeling"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
