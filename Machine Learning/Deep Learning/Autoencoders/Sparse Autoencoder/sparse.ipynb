{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea7fa590",
   "metadata": {},
   "source": [
    "1. [Sparse Autoencoder](#sparse-autoencoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c428da58",
   "metadata": {},
   "source": [
    "#### Sparse Autoencoder:\n",
    "- the hidden layer (bottleneck or other hidden layers) can have more neurons than the input layer\n",
    "- used in feature selection, anomaly detection, dimensionality reduction\n",
    "- sparsity constraint is added to loss function to prevent learning the identity function. \n",
    "    - learning identity function means just copying the input to the output without any compression or feature extraction\n",
    "- constraint encourages only a small fraction of the neurons in a hidden layer to be \"active\". By adding a penalty term to the loss function using L1 regularization or Kullback-Leibler (KL) divergence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25bb4e56",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
