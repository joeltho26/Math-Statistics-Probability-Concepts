{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6953080c",
   "metadata": {},
   "source": [
    "1. [Spectral Clustering](#spectral-clustering)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spectral Clustering:\n",
    "- it is an unsupervised ML\n",
    "- used to cluster data points into specific groups based on the similarities\n",
    "- used to cluster data that is complex and non linear in shape\n",
    "- leverages the principle of graph spectral theory\n",
    "    - treading datapoints as nodes in a graph\n",
    "    - using graph properties such as eigen values and eigen vectors of Laplacian matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 4 stages of Spectral clustering are,\n",
    "- Graph construction:\n",
    "    - data points are node in the graph\n",
    "    - edges are the similarities or affinity of the 2 data points\n",
    "        - some of the techniques to connect data points i.e. edges\n",
    "            - Epsilon neighborhood graph:\n",
    "                - connects data points using certain radius\n",
    "            - K Nearest Neighbor:\n",
    "                - connects each data point to its nearest neighbour \n",
    "            - Fully Connected Graph:\n",
    "                - the edge weight is determined by similarity function like Gaussian Kernel i.e. similar to the kernels used in SVM\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Affinity Matrix and Graph Laplacian:\n",
    "    - Affinity Matrix:\n",
    "        - the similarities between all data points are stored in affinity matrix or weight matrix or similarity matrix\n",
    "    - Degree Matrix:\n",
    "        - a degree matrix D is a diagonal matrix, each diagonal element is the sum of weights of all edges connected to node i\n",
    "    - Graph Laplacian matrix:\n",
    "        - graph laplacian matrix L is computed from affinity matrix and the degree matrix\n",
    "        - types of laplacian matrix:\n",
    "            - un-normalized: L => D - W\n",
    "            - normalized:\n",
    "                - Lnorm = D^-1/2 * LD^-1/2 = I - D^-1/2 * WD^-1/2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Eigen Decomposition of the Laplacian Matrix:\n",
    "    - compute the eigenvalues and eigenvectors of the Graph Laplacian matrix\n",
    "    -  eigenvectors associated with the smallest eigenvalues (excluding the eigenvalue 0) provide information about the underlying structure of the graph and the relationships between the data point"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e461209",
   "metadata": {},
   "source": [
    "- Dimensionality Reduction and Clustering:\n",
    "    - k eigenvectors corresponding to the k smallest (or largest, depending on the Laplacian form used) eigenvalues, where k is the desired number of clusters\n",
    "    - these k eigenvectors form a new, lower-dimensional representation of the data. Each data point is now represented by a row in a new matrix formed by these eigenvectors\n",
    "    - finally, a traditional clustering algorithm, such as K-Means, is applied to these new data representations in the lower-dimensional space to obtain the final clusters. The intuition is that in this new space, data points belonging to the same cluster will be closer to each other, even if they were not in the original high-dimensional space"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
